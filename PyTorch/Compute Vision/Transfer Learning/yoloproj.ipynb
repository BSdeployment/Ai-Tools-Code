{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d31c833",
   "metadata": {},
   "source": [
    "# <div dir=\"rtl\">×¢×‘×•×“×” ×¢× YOLO ×›×•×œ×œ ×“×•×’×××•×ª</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06637225",
   "metadata": {},
   "source": [
    "#### <div dir=\"rtl\">×˜×¢×™× ×ª ×”××•×“×œ = https://docs.ultralytics.com/models/yolo11/</div>\n",
    "<div dir=\"rtl\">×©×™××• ×œ×‘ × ×¢×©×” ×›××Ÿ ×©×™××•×© ×‘××•×“×œ YOLO11n ×œ×“×™×•×§ ×’×‘×•×” ×™×•×ª×¨ ×¢×‘×¨×• ×œ××•×“×œ×™× ×—×–×§×™× ×™×•×ª×¨ ×›×’×•×Ÿ ××•×“×œ ×” small medium ×•×›×“×•</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61248f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae78c78",
   "metadata": {},
   "source": [
    "#### ××©×™××” ×¨××©×•× ×” ×‘×“×™×§×” ×¢× ×™×© ××“× ×‘×ª××•× ×” ××• ×œ×\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea734cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(r\"<path>\")\n",
    "for r in results:\n",
    "    labels = [model.names[int(c)] for c in r.boxes.cls]\n",
    "    if \"person\" in labels:\n",
    "        print(\"×™×© ××“× ×‘×ª××•× ×”\")\n",
    "    else:\n",
    "        print(\"××™×Ÿ ××“× ×‘×ª××•× ×”\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b98e7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_preson(images):\n",
    "\n",
    "    for img in images:\n",
    "\n",
    "        results = model.predict(img)\n",
    "        for r in results:\n",
    "            labels = [model.names[int(c)] for c in r.boxes.cls]\n",
    "            print(img)\n",
    "            if \"person\" in labels:\n",
    "                print(\"×™×© ××“× ×‘×ª××•× ×”\")\n",
    "            else:\n",
    "                print(\"××™×Ÿ ××“× ×‘×ª××•× ×”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d535bab",
   "metadata": {},
   "source": [
    "### ×‘×“×™×§×ª ×“×™×•×§ × ×ª×•× ×™ ××•×“×œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d180c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "\n",
    "# ×”×’×“×¨ ××ª × ×ª×™×‘ ×”×ª×™×§×™×”\n",
    "folder_path = r\"<>\"\n",
    "\n",
    "# ×©××•×ª ×”××—×œ×§×•×ª ×©×× ×—× ×• ×¨×•×¦×™× ×œ×‘×“×•×§ (×œ×“×•×’××”: 'person')\n",
    "target_classes = ['person']\n",
    "\n",
    "# ×¡×¤×™×¨×”\n",
    "total_images = 0\n",
    "detected_images = 0\n",
    "\n",
    "# ×¢×‘×•×¨ ×›×œ ×§×•×‘×¥ ×‘×ª×™×§×™×™×”\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "        total_images += 1\n",
    "        image_path = os.path.join(folder_path, filename)\n",
    "        results = model(image_path)\n",
    "\n",
    "        found = False\n",
    "        for result in results:\n",
    "            boxes = result.boxes\n",
    "            if boxes is not None:\n",
    "                for cls_tensor in boxes.cls:\n",
    "                    class_id = int(cls_tensor.item())\n",
    "                    class_name = model.names[class_id]\n",
    "                    if class_name in target_classes:\n",
    "                        found = True\n",
    "                        break\n",
    "\n",
    "        if found:\n",
    "            detected_images += 1\n",
    "\n",
    "# ×”×¦×’ ××—×•×– ×“×™×•×§ ×‘×¡×™×¡×™\n",
    "accuracy = (detected_images / total_images) * 100\n",
    "print(f\"Detected 'person' in {detected_images} out of {total_images} images.\")\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01cee85",
   "metadata": {},
   "source": [
    "### ×¡×¤×™×¨×ª ×›××•×ª ×× ×©×™× ×‘×ª××•× ×”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddc43f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count person\n",
    "\n",
    "persons = model.predict(r\"<>\")\n",
    "\n",
    "person_count = 0\n",
    "\n",
    "\n",
    "for result in persons:\n",
    "    boxes = result.boxes\n",
    "    if boxes is not None:\n",
    "        for cls_tensor in boxes.cls:\n",
    "            class_id = int(cls_tensor.item())\n",
    "            class_name = model.names[class_id]\n",
    "            if class_name == 'person':\n",
    "                person_count += 1\n",
    "\n",
    "print(f\"Number of people in the image: {person_count}\")\n",
    "\n",
    "persons[0].show()  # Show the first result with detected persons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58b698",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    labels = [model.names[int(c)]for c in r.boxes.cls]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b4c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a46c94",
   "metadata": {},
   "source": [
    "### ×¡×™× ×•×Ÿ ×¤×¨×™×˜×™× ××¡×•×™×™××™×"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408164cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_classes = ['car']\n",
    "for result in results:\n",
    "    boxes = result.boxes\n",
    "    if boxes is not None:\n",
    "        keep = []\n",
    "        for i, cls_tensor in enumerate(boxes.cls):\n",
    "            class_id = int(cls_tensor.item())\n",
    "            class_name = model.names[class_id]\n",
    "            if class_name in allowed_classes:\n",
    "                keep.append(i)\n",
    "\n",
    "        # ×©××•×¨ ×¨×§ ××ª ×”×ª×™×‘×•×ª ×©×× ×—× ×• ×¨×•×¦×™×\n",
    "        if keep:\n",
    "            result.boxes = result.boxes[keep]\n",
    "        else:\n",
    "            result.boxes = None  # ××™×Ÿ ××” ×œ×”×¦×™×’\n",
    "\n",
    "# ×”×¦×’ ×¨×§ ××ª ×”×ª×™×‘×•×ª ×”××¡×•× × ×•×ª\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad13f2b",
   "metadata": {},
   "source": [
    "## Person Detect In Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b27378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# ×˜×¢×Ÿ ××ª ×”××•×“×œ\n",
    "\n",
    "# ×˜×¢×Ÿ ××ª ×”×•×•×™×“××•\n",
    "video_path = r'<path>'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# ×§×‘×œ ××ª ×§×¦×‘ ×”×¤×¨×™×™××™× ×œ×©× ×™×™×” (FPS)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_index = 0\n",
    "seconds_with_person = set()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ×©××•×¨ ××ª ×©× ×™×™×ª ×”×•×•×™×“××• ×”× ×•×›×—×™×ª\n",
    "    current_second = int(frame_index / fps)\n",
    "\n",
    "    # ×©××•×¨ ××ª ×”×ª××•× ×” ×œ×§×•×‘×¥ ×–×× ×™ ×× ××ª×” ×¢×•×‘×“ ×¢× ××•×“×œ YOLO ×©××§×‘×œ path\n",
    "    results = model(frame)\n",
    "\n",
    "    # ×‘×“×•×§ ×× ×™×© ××“× ×‘×¤×¨×™×™×\n",
    "    person_found = False\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for cls_tensor in boxes.cls:\n",
    "                class_id = int(cls_tensor.item())\n",
    "                class_name = model.names[class_id]\n",
    "                if class_name == 'person':\n",
    "                    person_found = True\n",
    "                    break\n",
    "\n",
    "    if person_found:\n",
    "        seconds_with_person.add(current_second)\n",
    "\n",
    "    frame_index += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# ×”×“×¤×¡×ª ×”×©× ×™×•×ª ×©×‘×”×Ÿ ×”×•×¤×™×¢ ××“×\n",
    "print(\"Seconds in which a person was detected:\")\n",
    "for sec in sorted(seconds_with_person):\n",
    "    print(f\"Second: {sec}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a8397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# ×˜×¢×Ÿ ××ª ××•×“×œ YOLO\n",
    "\n",
    "\n",
    "# ×¦×•×¨ ×ª×™×§×™×” ×œ×©××™×¨×ª ×”×ª××•× ×•×ª ×× ×œ× ×§×™×™××ª\n",
    "output_dir = 'captured_frames'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ×”×ª×—×‘×¨ ×œ××¦×œ××ª ×”××—×©×‘ (0 ×–×” ×”××¦×œ××” ×”×¨××©×™×ª)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "print(\"â³ ×××–×™×Ÿ ×œ××¦×œ××”... ×™×œ×›×•×“ ×¤×¨×™×™××™× ×›×©××“× ××•×¤×™×¢\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ×©×œ×— ××ª ×”×¤×¨×™×™× ×œ×–×™×”×•×™\n",
    "    results = model(frame)\n",
    "\n",
    "    person_detected = False\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for cls_tensor in boxes.cls:\n",
    "                class_id = int(cls_tensor.item())\n",
    "                class_name = model.names[class_id]\n",
    "                if class_name == 'person':\n",
    "                    person_detected = True\n",
    "                    break\n",
    "\n",
    "    if person_detected:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        filename = os.path.join(output_dir, f'person_{timestamp}.jpg')\n",
    "        cv2.imwrite(filename, frame)\n",
    "        print(f\"ğŸ“¸ ××“× ×–×•×”×”! ×ª××•× ×” × ×©××¨×”: {filename}\")\n",
    "\n",
    "    # ×™×¦×™××” ×¢×œ ×™×“×™ ×œ×—×™×¦×” ×¢×œ ××§×© q\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1441de4",
   "metadata": {},
   "source": [
    "### ×œ×›×™×“×ª ××“× ×‘×•×“××•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ded3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ×˜×¢×Ÿ ××ª ×”××•×“×œ\n",
    "\n",
    "\n",
    "# ×¤×ª×— ××ª ×”××¦×œ××”\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# ×¤×¨×˜×™× ×˜×›× ×™×™× ×©×œ ×”×•×•×™×“××•\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS) or 30)\n",
    "\n",
    "# ×¦×•×¨ ×ª×™×§×™×”\n",
    "output_dir = 'final_video_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ×©× ×”×§×•×‘×¥ ×”×¡×•×¤×™\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_path = os.path.join(output_dir, f'people_detected_{timestamp}.mp4')\n",
    "\n",
    "# ×”×’×“×¨×ª ×”Ö¾VideoWriter (×”×§×œ×˜×” ×œ×§×•×‘×¥)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "print(\"ğŸ¥ ×”×ª×—×‘×¨×•×ª ×œ××¦×œ××”... ×”×§×œ×˜×ª ×¤×¨×™×™××™× ×¢× ××“× ×‘×œ×‘×“.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ×‘×¦×¢ ×ª×—×–×™×ª ×¢× YOLO\n",
    "    results = model(frame)\n",
    "    person_detected = False\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for cls_tensor in boxes.cls:\n",
    "                cls_id = int(cls_tensor.item())\n",
    "                class_name = model.names[cls_id]\n",
    "                if class_name == 'person':\n",
    "                    person_detected = True\n",
    "                    break\n",
    "\n",
    "    # ×›×ª×•×‘ ×¤×¨×™×™× ×œ×§×•×‘×¥ ×¨×§ ×× ×–×•×”×” ××“×\n",
    "    if person_detected:\n",
    "        video_writer.write(frame)\n",
    "        print(\"ğŸ§ ××“× ×–×•×”×” â€” ×¤×¨×™×™× × ×©××¨.\")\n",
    "\n",
    "    # ×™×¦×™××” ×‘×œ×—×™×¦×” ×¢×œ 'q'\n",
    "    cv2.imshow(\"Live Feed\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ×¡×™×•×\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"âœ… ×•×™×“××• ×¡×•×¤×™ × ×©××¨: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb513fc2",
   "metadata": {},
   "source": [
    "âœ… ×ª×¨×’×™×œ 1: ×—×™×ª×•×š ×•×©××™×¨×ª ×”××•×‘×™×™×§×˜×™× ×›×§×‘×¦×™× × ×¤×¨×“×™×"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853bb615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# ×˜×¢×Ÿ ××ª ×”××•×“×œ\n",
    "\n",
    "\n",
    "# ×˜×¢×Ÿ ×ª××•× ×”\n",
    "image_path = r\"<>\"\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# ×”×¨×¥ ×–×™×”×•×™\n",
    "results = model(image)[0]\n",
    "\n",
    "# ×ª×™×§×™×™×” ×œ×©××™×¨×ª ××•×‘×™×™×§×˜×™×\n",
    "output_folder = \"cropped_objects\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ×—×™×ª×•×š ×•×©××™×¨×”\n",
    "for i, box in enumerate(results.boxes):\n",
    "    x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "    class_id = int(box.cls[0])\n",
    "    class_name = model.names[class_id]\n",
    "\n",
    "    cropped = image[y1:y2, x1:x2]\n",
    "    filename = f\"{output_folder}/{class_name}_{i}.jpg\"\n",
    "    cv2.imwrite(filename, cropped)\n",
    "    print(f\"âœ”ï¸ × ×©××¨: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49678e6b",
   "metadata": {},
   "source": [
    "âœ… ×ª×¨×’×™×œ 2: ××¢×¨×›×ª ×”×ª×¨××” ×‘×–××Ÿ ×××ª ×œ×–×™×”×•×™ ××•×‘×™×™×§×˜ ××¡×•×™× (×œ××©×œ ××“×)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "# from playsound import playsound  # pip install playsound\n",
    "import threading\n",
    "\n",
    "# ×˜×¢×Ÿ ××•×“×œ\n",
    "model = YOLO(\"yolov8n.pt\")\n",
    "target_class_name = \"person\"  # ×¢×¦× ×©×¦×¨×™×š ×œ×”×ª×¨×™×¢ ×¢×œ×™×•\n",
    "\n",
    "# ×“×’×œ ×”×ª×¨××”\n",
    "alert_triggered = False\n",
    "\n",
    "# ×¤×•× ×§×¦×™×™×ª ×”×©××¢×ª ×¦×œ×™×œ ×¤×¢× ××—×ª ×‘×›×œ ×–×™×”×•×™\n",
    "# def play_alert():\n",
    "#     global alert_triggered\n",
    "#     if not alert_triggered:\n",
    "#         alert_triggered = True\n",
    "#         playsound(\"alert.mp3\")  # ×©×™× ×§×•×‘×¥ ×¦×œ×™×œ ×‘×©× ×–×” ×‘×ª×™×§×™×™×”\n",
    "#         alert_triggered = False\n",
    "\n",
    "\n",
    "\n",
    "def play_alert():\n",
    "    global alert_triggered\n",
    "    if not alert_triggered:\n",
    "        alert_triggered = True\n",
    "        # playsound(\"alert.mp3\")  # ×©×™× ×§×•×‘×¥ ×¦×œ×™×œ ×‘×©× ×–×” ×‘×ª×™×§×™×™×”\n",
    "        print(\"ğŸ”” ×”×ª×¨××”: ××“× ×–×•×”×”!\")\n",
    "        alert_triggered = False\n",
    "# ×”×ª×—×‘×¨×•×ª ×œ××¦×œ××”\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)[0]\n",
    "\n",
    "    for box in results.boxes:\n",
    "        class_id = int(box.cls[0])\n",
    "        class_name = model.names[class_id]\n",
    "\n",
    "        if class_name == target_class_name:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, class_name, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "\n",
    "            threading.Thread(target=play_alert).start()\n",
    "\n",
    "    cv2.imshow(\"Detection\", frame)\n",
    "    if cv2.waitKey(1) == 27:  # ESC ×œ×¡×™×•×\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da45caa2",
   "metadata": {},
   "source": [
    "### ×™×¦×™×¨×ª ×•×™×“××• ×¨×§ ××¤×¨×™×™××™× ×©××•×¤×™×¢ ×‘×”× ××“×"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bf9a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# ×˜×¢×Ÿ ××ª ×”××•×“×œ\n",
    "model = YOLO('yolo11n.pt')\n",
    "\n",
    "# ×¤×ª×— ××ª ×”××¦×œ××”\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# ×¤×¨×˜×™× ×˜×›× ×™×™× ×©×œ ×”×•×•×™×“××•\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS) or 30)\n",
    "\n",
    "# ×¦×•×¨ ×ª×™×§×™×”\n",
    "output_dir = 'final_video_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ×©× ×”×§×•×‘×¥ ×”×¡×•×¤×™\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "output_path = os.path.join(output_dir, f'people_detected_{timestamp}.mp4')\n",
    "\n",
    "# ×”×’×“×¨×ª ×”Ö¾VideoWriter (×”×§×œ×˜×” ×œ×§×•×‘×¥)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "print(\"ğŸ¥ ×”×ª×—×‘×¨×•×ª ×œ××¦×œ××”... ×”×§×œ×˜×ª ×¤×¨×™×™××™× ×¢× ××“× ×‘×œ×‘×“.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # ×‘×¦×¢ ×ª×—×–×™×ª ×¢× YOLO\n",
    "    results = model(frame)\n",
    "    person_detected = False\n",
    "\n",
    "    for result in results:\n",
    "        boxes = result.boxes\n",
    "        if boxes is not None:\n",
    "            for cls_tensor in boxes.cls:\n",
    "                cls_id = int(cls_tensor.item())\n",
    "                class_name = model.names[cls_id]\n",
    "                if class_name == 'person':\n",
    "                    person_detected = True\n",
    "                    break\n",
    "\n",
    "    # ×›×ª×•×‘ ×¤×¨×™×™× ×œ×§×•×‘×¥ ×¨×§ ×× ×–×•×”×” ××“×\n",
    "    if person_detected:\n",
    "        video_writer.write(frame)\n",
    "        print(\"ğŸ§ ××“× ×–×•×”×” â€” ×¤×¨×™×™× × ×©××¨.\")\n",
    "\n",
    "    # ×™×¦×™××” ×‘×œ×—×™×¦×” ×¢×œ 'q'\n",
    "    # cv2.imshow(\"Live Feed\", frame)\n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "\n",
    "    cv2.waitKey(1)\n",
    "\n",
    "# ×¡×™×•×\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"âœ… ×•×™×“××• ×¡×•×¤×™ × ×©××¨: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d1b177",
   "metadata": {},
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
